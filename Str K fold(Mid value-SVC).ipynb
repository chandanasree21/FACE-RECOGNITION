{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d68da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c82e927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_real(v):\n",
    "    return (np.sqrt(np.real(v)*2+np.imag(v)*2))\n",
    "def calculate_metrics(cm):\n",
    "    num_classes = cm.shape[0]\n",
    "    metrics = {}\n",
    "\n",
    "    for class_idx in range(num_classes):\n",
    "        true_positives = cm[class_idx, class_idx]\n",
    "        false_positives = np.sum(cm[:, class_idx]) - true_positives\n",
    "        false_negatives = np.sum(cm[class_idx, :]) - true_positives\n",
    "        total_samples = np.sum(cm)\n",
    "        true_negatives = total_samples-sum([true_positives,false_negatives,false_positives])\n",
    "\n",
    "        precision = true_positives / (true_positives + false_positives)\n",
    "        accuracy = true_positives / np.sum(cm[class_idx, :])\n",
    "        specificity = np.sum(true_positives / (true_positives + false_negatives)) / num_classes\n",
    "        sensitivity = np.sum(true_negatives / (true_negatives + false_positives)) / num_classes\n",
    "        balanced_accuracy = (specificity + sensitivity) / 2\n",
    "        f_score = 2 * (precision * sensitivity) / (precision + sensitivity)\n",
    "\n",
    "        metrics[class_idx] = {\n",
    "            'Precision': precision,\n",
    "            'Accuracy': accuracy,\n",
    "            'Specificity': specificity,\n",
    "            'Sensitivity': sensitivity,\n",
    "            'Balanced Accuracy': balanced_accuracy,\n",
    "            'F-Score': f_score\n",
    "        }\n",
    "\n",
    "    for class_idx, metrics in metrics.items():\n",
    "        print(f\"Metrics for Class {class_idx}:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric}: {value}\")    \n",
    "        print()\n",
    "# calculate_metrics(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7568569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"C:/Users/HP/Desktop/Brandnew_CBP/Dataset/c2.csv\")\n",
    "tdf=pd.read_csv(\"C:/Users/HP/Desktop/Brandnew_CBP/Dataset/testf.csv\")#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca9a44e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>616</th>\n",
       "      <th>617</th>\n",
       "      <th>618</th>\n",
       "      <th>619</th>\n",
       "      <th>620</th>\n",
       "      <th>621</th>\n",
       "      <th>622</th>\n",
       "      <th>623</th>\n",
       "      <th>624</th>\n",
       "      <th>625</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>94</td>\n",
       "      <td>81</td>\n",
       "      <td>86</td>\n",
       "      <td>93</td>\n",
       "      <td>113</td>\n",
       "      <td>133</td>\n",
       "      <td>134</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>105</td>\n",
       "      <td>102</td>\n",
       "      <td>92</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>95</td>\n",
       "      <td>107</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>92</td>\n",
       "      <td>85</td>\n",
       "      <td>94</td>\n",
       "      <td>102</td>\n",
       "      <td>112</td>\n",
       "      <td>135</td>\n",
       "      <td>136</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>105</td>\n",
       "      <td>102</td>\n",
       "      <td>88</td>\n",
       "      <td>77</td>\n",
       "      <td>81</td>\n",
       "      <td>94</td>\n",
       "      <td>105</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>68</td>\n",
       "      <td>91</td>\n",
       "      <td>84</td>\n",
       "      <td>83</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>109</td>\n",
       "      <td>100</td>\n",
       "      <td>96</td>\n",
       "      <td>94</td>\n",
       "      <td>85</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>86</td>\n",
       "      <td>84</td>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "      <td>105</td>\n",
       "      <td>113</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>98</td>\n",
       "      <td>100</td>\n",
       "      <td>92</td>\n",
       "      <td>80</td>\n",
       "      <td>77</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>82</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>85</td>\n",
       "      <td>109</td>\n",
       "      <td>120</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>98</td>\n",
       "      <td>101</td>\n",
       "      <td>92</td>\n",
       "      <td>78</td>\n",
       "      <td>74</td>\n",
       "      <td>83</td>\n",
       "      <td>94</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>73</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>35</td>\n",
       "      <td>58</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>77</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>75</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>33</td>\n",
       "      <td>42</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>76</td>\n",
       "      <td>53</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>38</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>87</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180</th>\n",
       "      <td>79</td>\n",
       "      <td>67</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>77</td>\n",
       "      <td>84</td>\n",
       "      <td>90</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181</th>\n",
       "      <td>77</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>43</td>\n",
       "      <td>68</td>\n",
       "      <td>...</td>\n",
       "      <td>77</td>\n",
       "      <td>83</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2182 rows × 626 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2   3   4   5    6    7    8    9  ...  616  617  618  619   \n",
       "0      1    0  102  94  81  86   93  113  133  134  ...  103  105  102   92  \\\n",
       "1      0    1   89  92  85  94  102  112  135  136  ...   99  105  102   88   \n",
       "2      1  100   68  91  84  83  111    0    0    2  ...  112  109  100   96   \n",
       "3      0    0  129  86  84  86   87  105  113  119  ...   92   98  100   92   \n",
       "4      2    2   93  82  80  90   85  109  120  125  ...   90   98  101   92   \n",
       "...   ..  ...  ...  ..  ..  ..  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "2177  73   34    5  18  19   7   19   35   58   78  ...   81   77   87    0   \n",
       "2178  75   37    8   8  15  18   17   33   42   66  ...   84   77   88    0   \n",
       "2179  76   53   13   0  16  16   11   25   38   65  ...   75   87   91    0   \n",
       "2180  79   67   11   4  20  12   21   24   38   62  ...   77   84   90  101   \n",
       "2181  77   43   10   4   9  13   23   21   43   68  ...   77   83   91    0   \n",
       "\n",
       "      620  621  622  623  624  625  \n",
       "0      82   83   95  107  117    1  \n",
       "1      77   81   94  105  111    1  \n",
       "2      94   85   96    0    0    1  \n",
       "3      80   77   86   96  120    1  \n",
       "4      78   74   83   94  114    1  \n",
       "...   ...  ...  ...  ...  ...  ...  \n",
       "2177    0    0    0    0    0   60  \n",
       "2178    0    0    0    0    0   60  \n",
       "2179    0    0    0    0    0   60  \n",
       "2180    0    0    0    0    0   60  \n",
       "2181    0    0    1    0    0   60  \n",
       "\n",
       "[2182 rows x 626 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using mid value approach\n",
    "mid_col=625//2\n",
    "for i in range(len(df.columns)-1):\n",
    "    if i==str(mid_col):\n",
    "        continue\n",
    "    df[str(i)]=abs(df[str(i)]-df[str(mid_col)])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1b61327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>616</th>\n",
       "      <th>617</th>\n",
       "      <th>618</th>\n",
       "      <th>619</th>\n",
       "      <th>620</th>\n",
       "      <th>621</th>\n",
       "      <th>622</th>\n",
       "      <th>623</th>\n",
       "      <th>624</th>\n",
       "      <th>625</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>89</td>\n",
       "      <td>90</td>\n",
       "      <td>33</td>\n",
       "      <td>49</td>\n",
       "      <td>57</td>\n",
       "      <td>52</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>21</td>\n",
       "      <td>53</td>\n",
       "      <td>75</td>\n",
       "      <td>77</td>\n",
       "      <td>73</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>91</td>\n",
       "      <td>77</td>\n",
       "      <td>76</td>\n",
       "      <td>85</td>\n",
       "      <td>82</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>106</td>\n",
       "      <td>100</td>\n",
       "      <td>97</td>\n",
       "      <td>96</td>\n",
       "      <td>89</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>72</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>82</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>87</td>\n",
       "      <td>77</td>\n",
       "      <td>74</td>\n",
       "      <td>82</td>\n",
       "      <td>92</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>64</td>\n",
       "      <td>93</td>\n",
       "      <td>86</td>\n",
       "      <td>88</td>\n",
       "      <td>110</td>\n",
       "      <td>112</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>87</td>\n",
       "      <td>75</td>\n",
       "      <td>72</td>\n",
       "      <td>82</td>\n",
       "      <td>94</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>72</td>\n",
       "      <td>82</td>\n",
       "      <td>86</td>\n",
       "      <td>84</td>\n",
       "      <td>106</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>96</td>\n",
       "      <td>89</td>\n",
       "      <td>77</td>\n",
       "      <td>72</td>\n",
       "      <td>81</td>\n",
       "      <td>94</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>109</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>110</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>108</td>\n",
       "      <td>111</td>\n",
       "      <td>...</td>\n",
       "      <td>89</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>76</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>118</td>\n",
       "      <td>119</td>\n",
       "      <td>120</td>\n",
       "      <td>119</td>\n",
       "      <td>120</td>\n",
       "      <td>119</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>118</td>\n",
       "      <td>119</td>\n",
       "      <td>120</td>\n",
       "      <td>119</td>\n",
       "      <td>120</td>\n",
       "      <td>119</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>118</td>\n",
       "      <td>119</td>\n",
       "      <td>120</td>\n",
       "      <td>119</td>\n",
       "      <td>120</td>\n",
       "      <td>119</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>117</td>\n",
       "      <td>118</td>\n",
       "      <td>119</td>\n",
       "      <td>118</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>117</td>\n",
       "      <td>119</td>\n",
       "      <td>118</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>71</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 626 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9  ...  616  617  618   \n",
       "0     90   89   90   33   49   57   52   40   37   27  ...   53   48   48  \\\n",
       "1      0    2   91   77   76   85   82  112    1    0  ...  106  100   97   \n",
       "2      0    0   86   72   87   87   82  109    0    1  ...   92   95   95   \n",
       "3      0    0   88   64   93   86   88  110  112  119  ...   92   96   96   \n",
       "4      1    1   91   72   82   86   84  106  117  117  ...   98   98   96   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "194  111  111  109  111  111  110  111  111  108  111  ...   89  118    0   \n",
       "195  118  119  120  119  120  119  120  120  120  120  ...  122    0    0   \n",
       "196  118  119  120  119  120  119  120  120  120  120  ...  122    0    0   \n",
       "197  118  119  120  119  120  119  120  120  120  120  ...  122    0    0   \n",
       "198  117  118  119  118  119  119  117  119  118  119  ...  125    0    0   \n",
       "\n",
       "     619  620  621  622  623  624  625  \n",
       "0     21   53   75   77   73   84    1  \n",
       "1     96   89   79   80   89  101    1  \n",
       "2     87   77   74   82   92  103    1  \n",
       "3     87   75   72   82   94  106    1  \n",
       "4     89   77   72   81   94  105    1  \n",
       "..   ...  ...  ...  ...  ...  ...  ...  \n",
       "194    0    0    0    0   93   76   60  \n",
       "195    0    0    0    1    0   73   60  \n",
       "196    0    0    0    1    0   73   60  \n",
       "197    0    0    0    1    0   73   60  \n",
       "198    0    0    0  128   71   70   60  \n",
       "\n",
       "[199 rows x 626 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using mid value approach\n",
    "# mid_col=625//2\n",
    "for i in range(len(tdf.columns)-1):\n",
    "    if i==str(mid_col):\n",
    "        continue\n",
    "    tdf[str(i)]=abs(tdf[str(i)]-tdf[str(mid_col)])\n",
    "tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "923c92ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = df.iloc[:,:-1],tdf.iloc[:,:-1],df.iloc[:,-1],tdf.iloc[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a7036cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "99.08466819221968\n",
      "Fold 2\n",
      "99.08466819221968\n",
      "Fold 3\n",
      "99.54128440366972\n",
      "Fold 4\n",
      "98.62385321100918\n",
      "Fold 5\n",
      "89.90825688073394\n"
     ]
    }
   ],
   "source": [
    "#stratified k fold using SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC()\n",
    "n_splits = 5\n",
    "best_acc=0\n",
    "skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "    \n",
    "best_train,best_test=None,None\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    X_train_fold, X_test_fold = X_train.iloc[train_index,:], X_train.iloc[test_index,:]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "    clf.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # predictioning on the testing data\n",
    "    y_pred = clf.predict(X_test_fold)\n",
    "    \n",
    "\n",
    "    cm = confusion_matrix(y_test_fold, y_pred)\n",
    "    \n",
    "    acc=accuracy_score(y_pred,y_test_fold)*100\n",
    "    if acc>best_acc:\n",
    "        best_train=train_index\n",
    "        best_test=test_index\n",
    "        best_acc=acc\n",
    "    print(acc)\n",
    "   \n",
    "\n",
    "\n",
    "# for i, accuracy in enumerate(fold_accuracy):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f980e130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.9954128440366973\n",
      "Metrics for Class 0:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 1:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 2:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 3:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 4:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 5:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 6:\n",
      "Precision: 1.0\n",
      "Accuracy: 0.95\n",
      "Specificity: 0.04318181818181818\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.04431818181818182\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 7:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 8:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 9:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 10:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 11:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 12:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 13:\n",
      "Precision: 1.0\n",
      "Accuracy: 0.95\n",
      "Specificity: 0.04318181818181818\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.04431818181818182\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 14:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 15:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 16:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 17:\n",
      "Precision: 0.9090909090909091\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045236013986013984\n",
      "Balanced Accuracy: 0.04534527972027972\n",
      "F-Score: 0.08618356683389887\n",
      "\n",
      "Metrics for Class 18:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 19:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 20:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 21:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_best, X_test_best = X_train.iloc[best_train,:], X_train.iloc[best_test,:]\n",
    "y_train_best, y_test_best = y_train.iloc[best_train], y_train.iloc[best_test]\n",
    "clf.fit(X_train_best,y_train_best)\n",
    "y_pred_best=clf.predict(X_test_best)\n",
    "cm=confusion_matrix(y_test_best,y_pred_best)\n",
    "print(\"accuracy score\",accuracy_score(y_test_best,y_pred_best))\n",
    "calculate_metrics(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c81c758c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.06532663316582915\n",
      "Metrics for Class 0:\n",
      "Precision: 1.0\n",
      "Accuracy: 0.7\n",
      "Specificity: 0.03333333333333333\n",
      "Sensitivity: 0.047619047619047616\n",
      "Balanced Accuracy: 0.04047619047619047\n",
      "F-Score: 0.0909090909090909\n",
      "\n",
      "Metrics for Class 1:\n",
      "Precision: nan\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.047619047619047616\n",
      "Balanced Accuracy: 0.023809523809523808\n",
      "F-Score: nan\n",
      "\n",
      "Metrics for Class 2:\n",
      "Precision: nan\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.047619047619047616\n",
      "Balanced Accuracy: 0.023809523809523808\n",
      "F-Score: nan\n",
      "\n",
      "Metrics for Class 3:\n",
      "Precision: 0.0\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.023683547493071302\n",
      "Balanced Accuracy: 0.011841773746535651\n",
      "F-Score: 0.0\n",
      "\n",
      "Metrics for Class 4:\n",
      "Precision: 0.0\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.047367094986142604\n",
      "Balanced Accuracy: 0.023683547493071302\n",
      "F-Score: 0.0\n",
      "\n",
      "Metrics for Class 5:\n",
      "Precision: 0.0\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.042328042328042326\n",
      "Balanced Accuracy: 0.021164021164021163\n",
      "F-Score: 0.0\n",
      "\n",
      "Metrics for Class 6:\n",
      "Precision: 0.0\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.03955656336608718\n",
      "Balanced Accuracy: 0.01977828168304359\n",
      "F-Score: 0.0\n",
      "\n",
      "Metrics for Class 7:\n",
      "Precision: nan\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.047619047619047616\n",
      "Balanced Accuracy: 0.023809523809523808\n",
      "F-Score: nan\n",
      "\n",
      "Metrics for Class 8:\n",
      "Precision: 0.0\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.047367094986142604\n",
      "Balanced Accuracy: 0.023683547493071302\n",
      "F-Score: 0.0\n",
      "\n",
      "Metrics for Class 9:\n",
      "Precision: 0.0\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.045351473922902494\n",
      "Balanced Accuracy: 0.022675736961451247\n",
      "F-Score: 0.0\n",
      "\n",
      "Metrics for Class 10:\n",
      "Precision: nan\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.047619047619047616\n",
      "Balanced Accuracy: 0.023809523809523808\n",
      "F-Score: nan\n",
      "\n",
      "Metrics for Class 11:\n",
      "Precision: 1.0\n",
      "Accuracy: 0.1\n",
      "Specificity: 0.004761904761904762\n",
      "Sensitivity: 0.047619047619047616\n",
      "Balanced Accuracy: 0.026190476190476188\n",
      "F-Score: 0.0909090909090909\n",
      "\n",
      "Metrics for Class 12:\n",
      "Precision: nan\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.047619047619047616\n",
      "Balanced Accuracy: 0.023809523809523808\n",
      "F-Score: nan\n",
      "\n",
      "Metrics for Class 13:\n",
      "Precision: 0.07692307692307693\n",
      "Accuracy: 0.1\n",
      "Specificity: 0.004761904761904762\n",
      "Sensitivity: 0.044595616024187455\n",
      "Balanced Accuracy: 0.02467876039304611\n",
      "F-Score: 0.05645933014354067\n",
      "\n",
      "Metrics for Class 14:\n",
      "Precision: nan\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.047619047619047616\n",
      "Balanced Accuracy: 0.023809523809523808\n",
      "F-Score: nan\n",
      "\n",
      "Metrics for Class 15:\n",
      "Precision: nan\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.047619047619047616\n",
      "Balanced Accuracy: 0.023809523809523808\n",
      "F-Score: nan\n",
      "\n",
      "Metrics for Class 16:\n",
      "Precision: 0.21052631578947367\n",
      "Accuracy: 0.4\n",
      "Specificity: 0.01904761904761905\n",
      "Sensitivity: 0.04383975812547241\n",
      "Balanced Accuracy: 0.031443688586545726\n",
      "F-Score: 0.07256803253049733\n",
      "\n",
      "Metrics for Class 17:\n",
      "Precision: nan\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.047619047619047616\n",
      "Balanced Accuracy: 0.023809523809523808\n",
      "F-Score: nan\n",
      "\n",
      "Metrics for Class 18:\n",
      "Precision: nan\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.047619047619047616\n",
      "Balanced Accuracy: 0.023809523809523808\n",
      "F-Score: nan\n",
      "\n",
      "Metrics for Class 19:\n",
      "Precision: nan\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.047619047619047616\n",
      "Balanced Accuracy: 0.023809523809523808\n",
      "F-Score: nan\n",
      "\n",
      "Metrics for Class 20:\n",
      "Precision: nan\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.047619047619047616\n",
      "Balanced Accuracy: 0.023809523809523808\n",
      "F-Score: nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12504\\4291859585.py:14: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision = true_positives / (true_positives + false_positives)\n"
     ]
    }
   ],
   "source": [
    "y_pred_test=clf.predict(X_test)\n",
    "print(\"accuracy score\",accuracy_score(y_test,y_pred_test))\n",
    "cm=confusion_matrix(y_test,y_pred_test)\n",
    "calculate_metrics(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fd4593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
