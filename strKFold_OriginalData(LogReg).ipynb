{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "011c919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2a6b0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_real(v):\n",
    "    return (np.sqrt(np.real(v)*2+np.imag(v)*2))\n",
    "def calculate_metrics(cm):\n",
    "    num_classes = cm.shape[0]\n",
    "    metrics = {}\n",
    "\n",
    "    for class_idx in range(num_classes):\n",
    "        true_positives = cm[class_idx, class_idx]\n",
    "        false_positives = np.sum(cm[:, class_idx]) - true_positives\n",
    "        false_negatives = np.sum(cm[class_idx, :]) - true_positives\n",
    "        total_samples = np.sum(cm)\n",
    "        true_negatives = total_samples-sum([true_positives,false_negatives,false_positives])\n",
    "\n",
    "        precision = true_positives / (true_positives + false_positives)\n",
    "        accuracy = true_positives / np.sum(cm[class_idx, :])\n",
    "        specificity = np.sum(true_positives / (true_positives + false_negatives)) / num_classes\n",
    "        sensitivity = np.sum(true_negatives / (true_negatives + false_positives)) / num_classes\n",
    "        balanced_accuracy = (specificity + sensitivity) / 2\n",
    "        f_score = 2 * (precision * sensitivity) / (precision + sensitivity)\n",
    "\n",
    "        metrics[class_idx] = {\n",
    "            'Precision': precision,\n",
    "            'Accuracy': accuracy,\n",
    "            'Specificity': specificity,\n",
    "            'Sensitivity': sensitivity,\n",
    "            'Balanced Accuracy': balanced_accuracy,\n",
    "            'F-Score': f_score\n",
    "        }\n",
    "\n",
    "    for class_idx, metrics in metrics.items():\n",
    "        print(f\"Metrics for Class {class_idx}:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric}: {value}\")    \n",
    "        print()\n",
    "# calculate_metrics(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fd3247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"C:/Users/HP/Desktop/Brandnew_CBP/Dataset/c2.csv\")#train\n",
    "tdf=pd.read_csv(\"C:/Users/HP/Desktop/Brandnew_CBP/Dataset/testf.csv\")#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22eebf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = df.iloc[:,:-1],tdf.iloc[:,:-1],df.iloc[:,-1],tdf.iloc[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d60b64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.54233409610984\n",
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.31350114416476\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.77064220183486\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.85321100917432\n",
      "Fold 5\n",
      "88.9908256880734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Stratified k-fold with logReg\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# Classifier\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "\n",
    "#number of folds\n",
    "n_splits = 5\n",
    "best_acc=0\n",
    "\n",
    "# Initialize the Stratified K-Fold cross-validator\n",
    "skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "best_train,best_test=None,None\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    \n",
    "    # Spliting the data into training and testing sets for this fold\n",
    "    X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    # Fitting the  training data\n",
    "    clf.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # predictioning on the testing data\n",
    "    y_pred = clf.predict(X_test_fold)\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test_fold, y_pred)\n",
    "    acc=accuracy_score(y_pred,y_test_fold)*100\n",
    "    if acc>best_acc:\n",
    "        best_train=train_index\n",
    "        best_test=test_index\n",
    "        best_acc=acc\n",
    "    print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82c9c012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.9977064220183486\n",
      "Metrics for Class 0:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 1:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 2:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 3:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 4:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 5:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 6:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 7:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 8:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 9:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 10:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 11:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 12:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 13:\n",
      "Precision: 1.0\n",
      "Accuracy: 0.95\n",
      "Specificity: 0.04318181818181818\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.04431818181818182\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 14:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 15:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 16:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 17:\n",
      "Precision: 0.9523809523809523\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.04534527972027972\n",
      "Balanced Accuracy: 0.04539991258741259\n",
      "F-Score: 0.08656879872754296\n",
      "\n",
      "Metrics for Class 18:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 19:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 20:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 21:\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.045454545454545456\n",
      "F-Score: 0.08695652173913045\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X_train_best, X_test_best = X_train.iloc[best_train,:], X_train.iloc[best_test,:]\n",
    "y_train_best, y_test_best = y_train.iloc[best_train], y_train.iloc[best_test]\n",
    "clf.fit(X_train_best,y_train_best)\n",
    "y_pred_best=clf.predict(X_test_best)\n",
    "cm=confusion_matrix(y_test_best,y_pred_best)\n",
    "print(\"accuracy score\",accuracy_score(y_test_best,y_pred_best))\n",
    "calculate_metrics(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd805b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.16080402010050251\n",
      "Metrics for Class 0:\n",
      "Precision: 1.0\n",
      "Accuracy: 0.7\n",
      "Specificity: 0.031818181818181815\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.038636363636363635\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 1:\n",
      "Precision: nan\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.022727272727272728\n",
      "F-Score: nan\n",
      "\n",
      "Metrics for Class 2:\n",
      "Precision: nan\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.022727272727272728\n",
      "F-Score: nan\n",
      "\n",
      "Metrics for Class 3:\n",
      "Precision: 0.0\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.0404040404040404\n",
      "Balanced Accuracy: 0.0202020202020202\n",
      "F-Score: 0.0\n",
      "\n",
      "Metrics for Class 4:\n",
      "Precision: 0.0\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.04112554112554113\n",
      "Balanced Accuracy: 0.020562770562770564\n",
      "F-Score: 0.0\n",
      "\n",
      "Metrics for Class 5:\n",
      "Precision: 0.0\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.04473304473304473\n",
      "Balanced Accuracy: 0.022366522366522364\n",
      "F-Score: 0.0\n",
      "\n",
      "Metrics for Class 6:\n",
      "Precision: 0.14893617021276595\n",
      "Accuracy: 0.7\n",
      "Specificity: 0.031818181818181815\n",
      "Sensitivity: 0.03583453583453584\n",
      "Balanced Accuracy: 0.03382635882635883\n",
      "F-Score: 0.05776953114182061\n",
      "\n",
      "Metrics for Class 7:\n",
      "Precision: nan\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.022727272727272728\n",
      "F-Score: nan\n",
      "\n",
      "Metrics for Class 8:\n",
      "Precision: 0.08695652173913043\n",
      "Accuracy: 0.2\n",
      "Specificity: 0.009090909090909092\n",
      "Sensitivity: 0.0404040404040404\n",
      "Balanced Accuracy: 0.024747474747474747\n",
      "F-Score: 0.055172413793103454\n",
      "\n",
      "Metrics for Class 9:\n",
      "Precision: 0.0\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.04256854256854257\n",
      "Balanced Accuracy: 0.021284271284271284\n",
      "F-Score: 0.0\n",
      "\n",
      "Metrics for Class 10:\n",
      "Precision: nan\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.022727272727272728\n",
      "F-Score: nan\n",
      "\n",
      "Metrics for Class 11:\n",
      "Precision: 0.6\n",
      "Accuracy: 0.3\n",
      "Specificity: 0.013636363636363636\n",
      "Sensitivity: 0.04497354497354497\n",
      "Balanced Accuracy: 0.029304954304954303\n",
      "F-Score: 0.08367514356029532\n",
      "\n",
      "Metrics for Class 12:\n",
      "Precision: 0.0\n",
      "Accuracy: nan\n",
      "Specificity: nan\n",
      "Sensitivity: 0.04522613065326633\n",
      "Balanced Accuracy: nan\n",
      "F-Score: 0.0\n",
      "\n",
      "Metrics for Class 13:\n",
      "Precision: 1.0\n",
      "Accuracy: 0.3\n",
      "Specificity: 0.013636363636363636\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.029545454545454545\n",
      "F-Score: 0.08695652173913045\n",
      "\n",
      "Metrics for Class 14:\n",
      "Precision: 0.0\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.04353054353054353\n",
      "Balanced Accuracy: 0.021765271765271765\n",
      "F-Score: 0.0\n",
      "\n",
      "Metrics for Class 15:\n",
      "Precision: nan\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.022727272727272728\n",
      "F-Score: nan\n",
      "\n",
      "Metrics for Class 16:\n",
      "Precision: 0.0\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.045219029674988226\n",
      "Balanced Accuracy: 0.022609514837494113\n",
      "F-Score: 0.0\n",
      "\n",
      "Metrics for Class 17:\n",
      "Precision: 0.2222222222222222\n",
      "Accuracy: 1.0\n",
      "Specificity: 0.045454545454545456\n",
      "Sensitivity: 0.037037037037037035\n",
      "Balanced Accuracy: 0.041245791245791245\n",
      "F-Score: 0.06349206349206349\n",
      "\n",
      "Metrics for Class 18:\n",
      "Precision: nan\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.022727272727272728\n",
      "F-Score: nan\n",
      "\n",
      "Metrics for Class 19:\n",
      "Precision: 0.0\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.04521404521404521\n",
      "Balanced Accuracy: 0.022607022607022607\n",
      "F-Score: 0.0\n",
      "\n",
      "Metrics for Class 20:\n",
      "Precision: 0.0\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.04450757575757575\n",
      "Balanced Accuracy: 0.022253787878787876\n",
      "F-Score: 0.0\n",
      "\n",
      "Metrics for Class 21:\n",
      "Precision: nan\n",
      "Accuracy: 0.0\n",
      "Specificity: 0.0\n",
      "Sensitivity: 0.045454545454545456\n",
      "Balanced Accuracy: 0.022727272727272728\n",
      "F-Score: nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6396\\4291859585.py:14: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision = true_positives / (true_positives + false_positives)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6396\\4291859585.py:15: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  accuracy = true_positives / np.sum(cm[class_idx, :])\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6396\\4291859585.py:16: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  specificity = np.sum(true_positives / (true_positives + false_negatives)) / num_classes\n"
     ]
    }
   ],
   "source": [
    "y_pred_test=clf.predict(X_test)\n",
    "print(\"accuracy score\",accuracy_score(y_test,y_pred_test))\n",
    "cm=confusion_matrix(y_test,y_pred_test)\n",
    "calculate_metrics(cm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
